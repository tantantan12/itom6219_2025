{"cells":[{"cell_type":"markdown","metadata":{"id":"yQDZBgkbR_pY"},"source":["# Homework 3\n","\n","\n","Imagine you're a tech journalist at a major publication. Your editor has just greenlit your next big feature: a compelling deep-dive into OpenAI and Nvidia — two titans in the artificial intelligence space that have shaped the AI boom in dramatically different ways.\n","\n","On one hand, OpenAI is at the forefront of generative AI and large language models, capturing public imagination with ChatGPT and partnerships with Microsoft. On the other hand, Nvidia powers the hardware backbone of this revolution, producing the GPUs that fuel AI training at scale — and recently became one of the most valuable companies in the world.\n","\n","Beyond their core innovations, these companies also differ in how they engage with the public. Who is more influential on social media? Which brand has better engagement? Who reaches a broader audience through their content?\n","\n","In this assignment, you will:\n","\n","- Collect real Twitter data using the itom6219 package\n","- Analyze and compare the social presence, content strategy, engagement metrics, and popularity of OpenAI and Nvidia\n","- Apply techniques like TF-IDF vectorization, topic modeling, and regression analysis\n","- Draw data-driven conclusions on how these two companies communicate and influence in the digital space\n","\n"]},{"cell_type":"markdown","source":["## Step 1: Install ITOM6219 Package.\n","**You will need to install the itom6219 package to collect Twitter data.**"],"metadata":{"id":"08UbISbGW2aV"}},{"cell_type":"code","source":["!pip install --upgrade --force-reinstall git+https://github.com/tantantan12/itom6219.git > /dev/null 2>&1\n","!pip3 install pingouin\n","!pip install --upgrade --force-reinstall git+https://github.com/tantantan12/itom6219.git\n"],"metadata":{"id":"p1a29ZHiVnTu","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1743042173597,"user_tz":300,"elapsed":63030,"user":{"displayName":"Jane Tan","userId":"17747408632762818135"}},"outputId":"187ff67d-2dc4-41c8-b904-a23a6456c2cd"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[33mWARNING: Ignoring invalid distribution ~rllib3 (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n","\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~rllib3 (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n","\u001b[0mCollecting pingouin\n","  Downloading pingouin-0.5.5-py3-none-any.whl.metadata (19 kB)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from pingouin) (3.10.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from pingouin) (2.2.4)\n","Requirement already satisfied: pandas>=1.5 in /usr/local/lib/python3.11/dist-packages (from pingouin) (2.2.3)\n","Collecting pandas-flavor (from pingouin)\n","  Downloading pandas_flavor-0.6.0-py3-none-any.whl.metadata (6.3 kB)\n","Requirement already satisfied: scikit-learn>=1.2 in /usr/local/lib/python3.11/dist-packages (from pingouin) (1.6.1)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from pingouin) (1.14.1)\n","Requirement already satisfied: seaborn in /usr/local/lib/python3.11/dist-packages (from pingouin) (0.13.2)\n","Requirement already satisfied: statsmodels in /usr/local/lib/python3.11/dist-packages (from pingouin) (0.14.4)\n","Requirement already satisfied: tabulate in /usr/local/lib/python3.11/dist-packages (from pingouin) (0.9.0)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.5->pingouin) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.5->pingouin) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.5->pingouin) (2025.2)\n","Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.2->pingouin) (1.4.2)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.2->pingouin) (3.6.0)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->pingouin) (1.3.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->pingouin) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->pingouin) (4.56.0)\n","Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->pingouin) (1.4.8)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->pingouin) (24.2)\n","Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->pingouin) (11.1.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->pingouin) (3.2.1)\n","Requirement already satisfied: xarray in /usr/local/lib/python3.11/dist-packages (from pandas-flavor->pingouin) (2025.1.2)\n","Requirement already satisfied: patsy>=0.5.6 in /usr/local/lib/python3.11/dist-packages (from statsmodels->pingouin) (1.0.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=1.5->pingouin) (1.17.0)\n","Downloading pingouin-0.5.5-py3-none-any.whl (204 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m204.4/204.4 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pandas_flavor-0.6.0-py3-none-any.whl (7.2 kB)\n","\u001b[33mWARNING: Ignoring invalid distribution ~rllib3 (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n","\u001b[0mInstalling collected packages: pandas-flavor, pingouin\n","Successfully installed pandas-flavor-0.6.0 pingouin-0.5.5\n","\u001b[33mWARNING: Ignoring invalid distribution ~rllib3 (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n","\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~rllib3 (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n","\u001b[0mCollecting git+https://github.com/tantantan12/itom6219.git\n","  Cloning https://github.com/tantantan12/itom6219.git to /tmp/pip-req-build-76_y9ua0\n","  Running command git clone --filter=blob:none --quiet https://github.com/tantantan12/itom6219.git /tmp/pip-req-build-76_y9ua0\n","  Resolved https://github.com/tantantan12/itom6219.git to commit 6e152e1d8819c6e6dfcc862be6da3e2424fa22ec\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting requests (from itom6219==0.1)\n","  Using cached requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n","Collecting pandas (from itom6219==0.1)\n","  Using cached pandas-2.2.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (89 kB)\n","Collecting numpy>=1.23.2 (from pandas->itom6219==0.1)\n","  Using cached numpy-2.2.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n","Collecting python-dateutil>=2.8.2 (from pandas->itom6219==0.1)\n","  Using cached python_dateutil-2.9.0.post0-py2.py3-none-any.whl.metadata (8.4 kB)\n","Collecting pytz>=2020.1 (from pandas->itom6219==0.1)\n","  Using cached pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n","Collecting tzdata>=2022.7 (from pandas->itom6219==0.1)\n","  Using cached tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n","Collecting charset-normalizer<4,>=2 (from requests->itom6219==0.1)\n","  Using cached charset_normalizer-3.4.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (35 kB)\n","Collecting idna<4,>=2.5 (from requests->itom6219==0.1)\n","  Using cached idna-3.10-py3-none-any.whl.metadata (10 kB)\n","Collecting urllib3<3,>=1.21.1 (from requests->itom6219==0.1)\n","  Using cached urllib3-2.3.0-py3-none-any.whl.metadata (6.5 kB)\n","Collecting certifi>=2017.4.17 (from requests->itom6219==0.1)\n","  Using cached certifi-2025.1.31-py3-none-any.whl.metadata (2.5 kB)\n","Collecting six>=1.5 (from python-dateutil>=2.8.2->pandas->itom6219==0.1)\n","  Using cached six-1.17.0-py2.py3-none-any.whl.metadata (1.7 kB)\n","Using cached pandas-2.2.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1 MB)\n","Using cached requests-2.32.3-py3-none-any.whl (64 kB)\n","Using cached certifi-2025.1.31-py3-none-any.whl (166 kB)\n","Using cached charset_normalizer-3.4.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (143 kB)\n","Using cached idna-3.10-py3-none-any.whl (70 kB)\n","Using cached numpy-2.2.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.4 MB)\n","Using cached python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)\n","Using cached pytz-2025.2-py2.py3-none-any.whl (509 kB)\n","Using cached tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n","Using cached urllib3-2.3.0-py3-none-any.whl (128 kB)\n","Using cached six-1.17.0-py2.py3-none-any.whl (11 kB)\n","Building wheels for collected packages: itom6219\n","  Building wheel for itom6219 (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for itom6219: filename=itom6219-0.1-py3-none-any.whl size=2761 sha256=467aa38c9a713b263e4b922e4d9523f3557682f46f6b5e55e78c56ffceba31bd\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-jijk5536/wheels/85/b0/8f/0526c1033869bec00e4fcd411eaf1286a58550c082e280ad7d\n","Successfully built itom6219\n","\u001b[33mWARNING: Ignoring invalid distribution ~rllib3 (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n","\u001b[0mInstalling collected packages: pytz, urllib3, tzdata, six, numpy, idna, charset-normalizer, certifi, requests, python-dateutil, pandas, itom6219\n","  Attempting uninstall: pytz\n","    Found existing installation: pytz 2025.2\n","    Uninstalling pytz-2025.2:\n","      Successfully uninstalled pytz-2025.2\n","  Attempting uninstall: tzdata\n","    Found existing installation: tzdata 2025.2\n","    Uninstalling tzdata-2025.2:\n","      Successfully uninstalled tzdata-2025.2\n","  Attempting uninstall: six\n","    Found existing installation: six 1.17.0\n","    Uninstalling six-1.17.0:\n","      Successfully uninstalled six-1.17.0\n","  Attempting uninstall: numpy\n","\u001b[33m    WARNING: Ignoring invalid distribution ~rllib3 (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n","\u001b[0m    Found existing installation: numpy 2.2.4\n","    Uninstalling numpy-2.2.4:\n","      Successfully uninstalled numpy-2.2.4\n","  Attempting uninstall: idna\n","    Found existing installation: idna 3.10\n","    Uninstalling idna-3.10:\n","      Successfully uninstalled idna-3.10\n","  Attempting uninstall: charset-normalizer\n","    Found existing installation: charset-normalizer 3.4.1\n","    Uninstalling charset-normalizer-3.4.1:\n","      Successfully uninstalled charset-normalizer-3.4.1\n","  Attempting uninstall: certifi\n","    Found existing installation: certifi 2025.1.31\n","    Uninstalling certifi-2025.1.31:\n","      Successfully uninstalled certifi-2025.1.31\n","  Attempting uninstall: requests\n","    Found existing installation: requests 2.32.3\n","    Uninstalling requests-2.32.3:\n","      Successfully uninstalled requests-2.32.3\n","  Attempting uninstall: python-dateutil\n","    Found existing installation: python-dateutil 2.9.0.post0\n","    Uninstalling python-dateutil-2.9.0.post0:\n","      Successfully uninstalled python-dateutil-2.9.0.post0\n","  Attempting uninstall: pandas\n","    Found existing installation: pandas 2.2.3\n","    Uninstalling pandas-2.2.3:\n","      Successfully uninstalled pandas-2.2.3\n","  Attempting uninstall: itom6219\n","\u001b[33m    WARNING: Ignoring invalid distribution ~rllib3 (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n","\u001b[0m    Found existing installation: itom6219 0.1\n","    Uninstalling itom6219-0.1:\n","      Successfully uninstalled itom6219-0.1\n","\u001b[33mWARNING: Ignoring invalid distribution ~rllib3 (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n","\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~rllib3 (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n","\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~rllib3 (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n","\u001b[0m\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.2.3 which is incompatible.\n","numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.2.4 which is incompatible.\n","tensorflow 2.18.0 requires numpy<2.1.0,>=1.26.0, but you have numpy 2.2.4 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed certifi-2025.1.31 charset-normalizer-3.4.1 idna-3.10 itom6219-0.1 numpy-2.2.4 pandas-2.2.3 python-dateutil-2.9.0.post0 pytz-2025.2 requests-2.32.3 six-1.17.0 tzdata-2025.2 urllib3\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["certifi","dateutil","six"]},"id":"deb59c5b81714f1b84b2af5d58314f4a"}},"metadata":{}}]},{"cell_type":"markdown","source":["## Step 2: Account Summary Comparison\n","\n","You will need to collect Twitter account data and analyze the Twitter account data. This could be done by using the user_info function.\n","\n","- Write down your code to collect information about the Twitter account of nvidia by using function user_info from the package of itom6219.\n","- Print account information of OpenAI (save as user1) and nvidia (save as user2).\n","- What are the data types of user1 and user2?\n","- Print the column names of user1.\n","- print the followers_count for user1(OpenAI).\n","- print the followers_count for user2(nvidia).\n","- Generate a boolean variable OpenAI_greater_than_nvidia, which takes the value of True if OpenAI has more followers and False otherwise.\n","- retrieve the user ids of OpenAI and nvidia. It is stored in the column of \"id\".\n","\n","*Complete the above requirements using Python.*"],"metadata":{"id":"v_BDtk1MW8NX"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"mxan8y_hR_pa"},"outputs":[],"source":["# make sure you run the above block of code to install the user package itom6219.\n","import os\n","from google.colab import userdata\n","os.environ[\"BEARER_TOKEN\"] =userdata.get('BEARER_TOKEN')\n","\n","from itom6219 import user_info, user_tweets, user_tweets_all\n","\n","\n","user1=user_info([\"OpenAI\"])\n","\n","user2=  ### Write down your code to collect information about the Twitter account of nvidia.\n","\n","# Print account information of OpenAI and nvidia.\n","\n","# What is the data type of user1 and user2?\n","\n","# Print the column names of user1\n","\n","# print the followers_count for OpenAI\n","\n","# print the followers_count for nvidia\n","\n","\n","# generate a boolean variable OpenAI_greater_than_nvidia, which takes the value of True if OpenAI has more followers and False otherwise.\n","\n","# retrieve the user ids of OpenAI and nvidia. It is stored in the column of \"id\"."]},{"cell_type":"markdown","source":["## Step 3: 100 Tweets Comparison\n","\n","- Use the function user_tweets from the package itom6219 to retrieve 100 tweets generated by OpenAI and Nvidia. Save the result into \"tweets_openAI\" and \"tweets_nvidia\".\n","\n","- Use function head() to display the first five rows of these two dataframes.\n","\n","- Use function head(n) to display the irst n rows. Allow n to be 10.\n","\n","- Display the column names of the dataframes.\n","\n","- How many rows and columns are in tweets_openAI and tweets_nvidia?\n","\n","- Summarize tweets_openAI and tweets_nvidia using the function of describe. What's the comparison between average  public_metrics.impression_count and public_metrics.impression_count?\n","\n","- Display the text of tweet from OpenAI and Nvidia that has the highest public_metrics.bookmark_count and public_metrics.impression_count, and public_metrics.impression_count, respectively.\n","\n","- Generate a new column by using two existing columns to represent the ratio of likes over impression. Which tweet has the highest like ratio for OpenAI and Nvidia, respectively?\n","\n","*Complete the above requirements using Python.*"],"metadata":{"id":"XOgnUkLyXY2B"}},{"cell_type":"code","source":["# The instruction below are based on openAI; Repeat the process for Nvidia to answer the above questions.\n","\n","# Use the function user_tweets from the package itom6219 to retrieve tweets generated by OpenAI. Save the result into \"tweets_openAI\".\n","tweets_openAI=user_tweets([\"OpenAI\"], exclude_replies=True, exclude_retweets=True)\n","\n","# Use function head() to display the first five rows of tweets_openAI.\n","\n","# Use function head(n) to display the first n rows of tweets_openAI. Allow n to be 10.\n","\n","# Display the column names of tweets_openAI.\n","\n","# How many rows and columns are in tweets_openAI?\n","\n","# Summarize the tweets_openAI using the function of describe. What's the average  public_metrics.impression_count and public_metrics.impression_count?\n","\n","# Display the text of tweet that has the highest public_metrics.bookmark_count and public_metrics.impression_count, and public_metrics.impression_count, respectively.\n","\n","# Generate a new column by using two existing columns to represent the ratio of likes over impression. Which tweet has the highest like ratio?\n","\n","tweets_openAI['like_ratio']=\n"],"metadata":{"id":"5COtNqWhVJT0"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"96a1pvpYR_pb"},"source":["## Step 4: Large Data Comparison\n","\n","In the previous step, you were able to collectt 100 tweets from OpenAI. Moving forward, use the tweets_openAI.csv and tweets_nvidia.csv, which contain 1500 tweets each. Due to theAPI rate limit, this data is provided to you; you do not need to collect the data by yourself.\n","\n","- Twitter (now X) began tracking public_metrics.impression_count only in recent years. As a result, older tweets may have a value of zero for impressions. Check the minimum value of public_metrics.impression_count in your dataset. Filter out tweets with zero impressions from both tweets_openAI and tweets_nvidia. Use the updated data (with only non-zero impressions) for all analysis moving forward."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CL84bg7_R_pc"},"outputs":[],"source":["import pandas as pd\n","df=pd.read_csv('tweets_openAI.csv')\n","df\n","\n","#Twitter (now X) began tracking public_metrics.impression_count only in recent years. As a result, older tweets may have a value of zero for impressions.\n","# Step 1: Check the minimum value of public_metrics.impression_count in your dataset.\n","# Step 2: Filter out tweets with zero impressions from both tweets_openAI and tweets_nvidia.\n","# Use the updated data (with only non-zero impressions) for all analysis moving forward.\n","\n"]},{"cell_type":"markdown","source":["## Step 5. Data visualization\n","\n","Modify the code from class exercise to visualize the log(impression+1) and log(like+1) for Twitter and Nvidia over time.\n","\n","Tip: use pd.to_datetime to convert \"created_at\" before using it as x-axis."],"metadata":{"id":"GDv4PulJxmR9"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"4o9BitMQR_pc"},"outputs":[],"source":["import plotly.express as px\n","\n","# create a line plot with Plotly Express\n","fig = ## Type Your Code Here. Use function px.line from Plotly Express.\n","\n","# display the plot\n","fig.show()\n"]},{"cell_type":"markdown","metadata":{"id":"pJJM2dgqR_pc"},"source":["## Step 6: Vectorization\n","\n","Next, we will vectorize the tweet content by generating a document-term matrix with TF-IDF scoress.\n","- We remove English stopwords.\n","- max_df=0.8\n","- min_df=0.02"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5slbp8mjR_pc"},"outputs":[],"source":["from sklearn.feature_extraction.text import TfidfVectorizer\n","docs=df['text']\n","tfidf_vectorizer = ## Please Type Your Code Here.\n","tfidf = ## Please Type Your Code Here.\n","\n","\n","tfidf_df = ## Please Type Your Code Here.\n","tfidf_df"]},{"cell_type":"markdown","metadata":{"id":"FCP-_xHDR_pc"},"source":["## Step 7. Topic Discovery\n","We use non-negative matrix factorization to generate 20 topics.\n","For each topic, we use the top 3 words to describe the topic."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4yL18PlBR_pc"},"outputs":[],"source":["# Apply NMF\n","from sklearn.decomposition import NMF\n","\n","nmf_model = ## Please Type Your Code Here.\n","nmf_model.fit(tfidf)\n","W =## Please Type Your Code Here to generate the document-topic matrix\n","\n","# Display topics\n","feature_names = tfidf_vectorizer.get_feature_names_out()\n","topic_names=[]\n","## Please Type Your Code Here to generate and print topic names for each topic."]},{"cell_type":"markdown","metadata":{"id":"_ceTwyFIR_pd"},"source":["## Step 8 Linear Regression\n","Model\n","Construct out outcome variable $log(Likes)=log(Likes+1)$, run the model, and evaluate the model.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4R31QmVLR_pd"},"outputs":[],"source":["# Code for estimating the linear regression model with the outcome being $log(Likes)$\n","\n","## Please Type Your Code Here\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-FryuRoaR_pd"},"outputs":[],"source":["# Code for results production\n","\n","\n","## Please Type Your Code Here"]},{"cell_type":"markdown","source":["Please fill in the text box with your interpretation of the estimates.\n","### Coefficients interpretation.\n","---\n","\n","```\n","+------------------------------------+\n","| Interpret the coefficients here.   |\n","+------------------------------------+\n","```\n","\n"],"metadata":{"id":"F6eY4KDryS3O"}},{"cell_type":"markdown","source":["Please fill in the text box with your interpretation of the R2.\n","\n","### R2 Interpretation.\n","---\n","\n","```\n","+---------------------------------------------------------------------------+\n","| Input Your Answers Here.                                                  |\n","| - Interpret the R2.                                                       |\n","| - Change the number of components to 10 and 5. How would that affect R2?  |\n","+---------------------------------------------------------------------------+\n","```\n"],"metadata":{"id":"I1fCSazMyfdG"}},{"cell_type":"markdown","metadata":{"id":"_xRZ1DQIR_pd"},"source":["## Step 9: Perform the same analysis for the outcome of impression based on tweets from OpenAI.\n","\n","```\n","+-------------------------------------------------------------------------+\n","| No code is required but you will need to keep the regression results.   |\n","+-------------------------------------------------------------------------+\n","```\n"]},{"cell_type":"markdown","source":["## Step 10: Topic modeling and regression for the outcome of impression and likes based on tweets from Nvidia.\n","\n","```\n","+-------------------------------------------------------------------------+\n","| No code is required but you will need to keep the regression results.   |\n","+-------------------------------------------------------------------------+\n","```\n","\n","## Step 11: Summarize your findings based on the comparison between Nvidia and OpenAI.\n","```\n","+----------------------------+\n","| Input Your Answers Here.   |\n","+----------------------------+\n","```"],"metadata":{"id":"IeNUKnUdyxTP"}}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.6"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}